# Training Guide

## Deploy K3s

For this you'll need a Linux system you can SSH into. We'll use the `k3sup` command available from [k3sup.dev](https://k3sup.dev). The defaults assume that you're using `~/.ssh/id_rsa` as your key and connecting as the `root` user. If you need to change these or other defaults, see the output from `k3sup install --help`.

All `k3sup` needs to install K3s over SSH is the IP of the destination server. We're adding a release channel to make sure that we're running the `stable` release, and not the `latest`.

```bash
# replace this with the IP of your host
export IP=10.68.0.143
k3sup install --ip=$IP --k3s-channel=stable
```

## Kubernetes

### Pod

```bash
kubectl apply -f pod/pod.yaml
kubectl logs myapp-pod
kubectl get po -w
kubectl delete po myapp-pod
```

### Deployment

We can launch random stuff, but this isn't repeatable.

``` bash
kubectl create deploy nginx --image=nginx:1.16-alpine
kubectl get deploy
kubectl get po
kubectl delete deploy/nginx
```

Launch again using kustomize templates.


```bash
kubectl create deploy nginx --image=nginx:1.16-alpine --dry-run -o yaml > deployment/base/deployment.yaml
kubectl apply -k deployment/base
kubectl get deploy
kubectl get po
```

- describe pod, look at the image
- scale deployment manually

``` bash
kubectl scale deploy/nginx --replicas=3
kubectl rollout status deploy/nginx
kubectl get deploy
kubectl get po
```

- upgrade with bad image

``` bash
kubectl set image deploy/nginx nginx=nginx:1.17-alpne --record
kubectl rollout status deploy/nginx
kubectl get po
kubectl rollout undo deploy/nginx
```

- redo upgrade from manifest

``` bash
kustomize build deployment/base
```

- edit base to change image and then apply

```bash
kubectl apply -k deployment/base
```

- how can we use this for different environments?

```bash
kustomize build deployment/overlay/staging
kustomize build deployment/overlay/production

kubectl apply -k deployment/overlay/staging
kubectl apply -k deployment/overlay/production
kubectl get deploy
kubectl get pods
```

### ConfigMaps

- show ConfigMaps
- explain what they're for
- explain how they're generated by Kustomize
- they'll show up later

### Services

- show services listening as NodePort
- go look at them

``` bash
export PORT=$(kubectl get service/staging-nginx -o jsonpath='{.spec.ports[0].nodePort}')
curl -I $IP:$PORT
```

### Ingress

- show `deployment/overlay/ingress/single/ingress.yaml`

``` bash
kubectl apply -k deployment/overlay/ingress/single
kubectl get ingress
```

- visit <https://training-a.cl.monach.us>
- what about multiple apps?

``` bash
kustomize build deployment/overlay/ingress/fanout
kubectl apply -k deployment/overlay/ingress/fanout
```

- visit <https://training-a.cl.monach.us> (fail)
- visit <https://training.cl.monach.us/nginx> (works)
- deploy rancher-demo application

```bash
kustomize build rancher-demo/base
kubectl apply -k rancher-demo/base
```

- visit <https://training-a.cl.monach.us/>

## Rancher

### Server Deploy

```bash
helm repo add jetstack https://charts.jetstack.io
helm repo add rancher-stable https://releases.rancher.com/server-charts/stable
helm repo update

kubectl create namespace cert-manager
kubectl create namespace cattle-system

helm install cert-manager jetstack/cert-manager --namespace cert-manager --set installCRDs=true

helm install rancher rancher-stable/rancher --namespace cattle-system --set hostname=rancher.$IP.xip.io
```

### Walkthrough

- Cluster Explorer
- Apps
- Continuous Delivery
